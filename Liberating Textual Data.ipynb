{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liberating Presidential Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the ProPublica API\n",
    "Saving this here just in case we want to use this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#key = 'KYXeq5PJ4PFO8sRiQTTLJH9v2SVrw7tubGzQ2jJ7'\n",
    "#url = 'https://api.propublica.org/congress/v1/115/senate/members.json'\n",
    "#import requests\n",
    "#headers = {\"X-API-Key\": key}\n",
    "#r = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#links = list(soup.find_all(\"a\", text='Text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Function to grab urls from a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extracturlfrom(string):\n",
    " #   while string[:4] != 'http':\n",
    "  #      string = string[1:]\n",
    "   # for i in range(len(string)):\n",
    "    #    if string[i] == '\"':\n",
    "     #       return string[:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Put all of these links in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#urllist = []\n",
    "#for i in links:\n",
    " #   urllist.append(extracturlfrom(str(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example of what a page looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example = requests.get(urllist[50])\n",
    "#newsoup = BeautifulSoup(example.content, 'html.parser')\n",
    "#print(newsoup.contents[50].get_text())\n",
    "#newsoup.contents[51].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example of using selenium in preparation for our webcrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexhtml = \"https://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CPD&browsePath=2018&isCollapsed=true&leafLevelBrowse=false&ycord=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_index = requests.get(indexhtml)\n",
    "#from bs4 import BeautifulSoup\n",
    "#soup = BeautifulSoup(year_index.content, 'html.parser')\n",
    "#soup.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"0088d3c8-20f5-4f24-a1a0-d74a373c77e4\", element=\"cd2a5b33-7727-4cbd-a9f1-05cb9cdfae9f\")>]\n"
     ]
    }
   ],
   "source": [
    "pres_page = webdriver.Firefox()\n",
    "pres_page.get(indexhtml)\n",
    "years=pres_page.find_elements_by_xpath(\".//div[@class='level1 browse-level']/a\")\n",
    "for year in range(0, len(years)):\n",
    "    years = pres_page.find_elements_by_xpath(\".//div[@class='level1 browse-level']/a\")\n",
    "    years[year].click()\n",
    "    months = pres_page.find_elements_by_xpath(\".//div[@class='level3 browse-leaf-level ']/a\")\n",
    "    print(months)\n",
    "    break\n",
    "    for month in range(0, len(months)):\n",
    "        months = pres_page.find_elements_by_xpath(\".//div[@class='level3 browse-level']/a\")\n",
    "        months[month].click()\n",
    "        pres_page.back()\n",
    "    pres_page.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/html/body/div[2]/table/tbody/tr/td[3]/div/div[3]/div[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
